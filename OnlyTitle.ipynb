{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a777229c-9ab7-43c4-ae3c-4ab4607da6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"##**Importing the tools**\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ffbd5bd-52cb-4452-9aed-85c1e9bbfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thunderbird\n",
    "df1=pd.read_csv(r'E:\\PycharmProjects\\duplicate bug report detection\\Duplicate Bug Report\\ThunderBird\\dup_TB.csv',delimiter=';')\n",
    "df2=pd.read_csv(r'E:\\PycharmProjects\\duplicate bug report detection\\Duplicate Bug Report\\ThunderBird\\Nondup_TB.csv',delimiter=';')\n",
    "\n",
    "\n",
    "df1['Label'] = 'duplicate'\n",
    "df2['Label'] = 'non duplicate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dbe3d73-4c7c-4c68-b995-7acd9fcba861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"##**Loading the Pre-trained BERT model**\"\"\"\n",
    "\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b72828-b067-4b2b-81ed-64982496893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **Remove stop words**\"\"\"\n",
    "\n",
    "df1['Title1']= df1['Title1'].str.replace(r'i' 'me' 'my' 'myself' 'we' \n",
    "                                         'our' 'ours' 'ourselves' 'you' 'your' 'yours' 'yourself''yourselves' 'they' 'we' 'him' 'he' 'him' 'his' 'himself' 'she' 'her' 'hers' 'herself' 'it''its' 'itself' 'they' 'them' 'their' 'theirs' 'themselves'  'what' 'which' 'who' 'whom' 'this' 'that'\n",
    "                                         'these' 'those' 'am' 'is' 'are' 'was' 'were' 'be' 'been' 'being' 'have' 'has' 'had' 'having' 'do' 'does' 'did' 'doing' 'a' 'an' 'the' 'and' 'but' 'if' 'or' 'because' 'as' 'until' 'while' 'of' 'at' 'by' 'for' 'with' 'about' 'against' 'between' 'into' 'through' \n",
    "                                         'during' 'before' 'after' 'above' 'below' 'to' 'from' 'up' 'down' 'in' 'out' 'on' 'off' 'over' 'under' 'again' 'further' 'then' 'once'  'here' 'there' 'when' 'where' 'why' 'how' 'all' 'any' 'both' 'each' 'few' 'more' 'most' 'other' 'some' 'such' 'no' 'nor' 'not' 'only' 'own' 'same' 'so' 'than' 'too' 'very' 's' 't' 'can' 'will' 'just' 'don' 'should' 'now'\n",
    "                                         'java' 'com' 'org' ,'')\n",
    "\n",
    "\n",
    "df1['Title2']= df1['Title2'].str.replace(r'i' 'me' 'my' 'myself' 'we' \n",
    "                                         'our' 'ours' 'ourselves' 'you' 'your' 'yours' 'yourself''yourselves' 'they' 'we' 'him' 'he' 'him' 'his' 'himself' 'she' 'her' 'hers' 'herself' 'it''its' 'itself' 'they' 'them' 'their' 'theirs' 'themselves'  'what' 'which' 'who' 'whom' 'this' 'that'\n",
    "                                         'these' 'those' 'am' 'is' 'are' 'was' 'were' 'be' 'been' 'being' 'have' 'has' 'had' 'having' 'do' 'does' 'did' 'doing' 'a' 'an'\n",
    "                                         'the' 'and' 'but' 'if' 'or' 'because' 'as' 'until' 'while' 'of' 'at' 'by' 'for' 'with' 'about' 'against' 'between' 'into' 'through' 'during' 'before' 'after' 'above' 'below' 'to' 'from' 'up' 'down' 'in' 'out' 'on' 'off' 'over' 'under' 'again' 'further' 'then' 'once' 'here' 'there' 'when' 'where' 'why' 'how' 'all' 'any' 'both' 'each' 'few' 'more' 'most' 'other' 'some' 'such' 'no' 'nor' 'not' 'only' 'own' \n",
    "                                         'same' 'so' 'than' 'too' 'very' 's' 't' 'can' 'will' 'just' 'don' 'should' 'now'\n",
    "                                         'java' 'com' 'org' ,'')\n",
    "\n",
    "df2['Title1']= df2['Title1'].str.replace(r'i' 'me' 'my' 'myself' 'we' 'our' 'ours' 'ourselves' 'you' 'your' 'yours' 'yourself''yourselves' 'they' 'we' 'him' 'he' 'him' 'his' 'himself' 'she'\n",
    "                                         'her' 'hers' 'herself' 'it''its' 'itself' 'they' 'them' 'their' 'theirs' 'themselves'  'what' 'which' 'who' 'whom' 'this' 'that' 'these' 'those' 'am' 'is' 'are' 'was' 'were' 'be' 'been' 'being' 'have' 'has' 'had' 'having' 'do' 'does' 'did' 'doing' 'a' 'an'\n",
    "                                         'the' 'and' 'but' 'if' 'or' 'because' 'as' 'until' 'while' 'of' 'at' 'by' 'for' 'with' 'about' 'against' 'between' 'into' 'through' \n",
    "                                         'during' 'before' 'after' 'above' 'below' 'to' 'from' 'up' 'down' 'in' 'out' 'on' 'off' 'over' 'under' 'again' 'further' 'then' 'once' 'here' 'there' 'when' 'where' 'why' 'how' 'all' 'any' 'both' 'each' 'few' 'more' 'most' 'other' 'some' 'such' 'no' 'nor' 'not' 'only' 'own' 'same' 'so' 'than' 'too' 'very' 's' 't' 'can' 'will' 'just' 'don' 'should' 'now'\n",
    "                                         'java' 'com' 'org' ,'')\n",
    "\n",
    "\n",
    "df2['Title2']= df2['Title2'].str.replace(r'i' 'me' 'my' 'myself' 'we' 'our' 'ours' 'ourselves' 'you' 'your' 'yours' 'yourself''yourselves' 'they' 'we' 'him' 'he' 'him' 'his' 'himself' 'she'\n",
    "                                         'her' 'hers' 'herself' 'it''its' 'itself' 'they' 'them' 'their' 'theirs' 'themselves'  'what' 'which' 'who' 'whom' 'this' 'that' 'these' 'those' 'am' 'is' 'are' 'was' 'were' 'be' 'been' 'being' 'have' 'has' 'had' 'having' 'do' 'does' 'did' 'doing' 'a' 'an'\n",
    "                                         'the' 'and' 'but' 'if' 'or' 'because' 'as' 'until' 'while' 'of' 'at' 'by' 'for' 'with' 'about' 'against' 'between' 'into' 'through' \n",
    "                                         'during' 'before' 'after' 'above' 'below' 'to' 'from' 'up' 'down' 'in' 'out' 'on' 'off' 'over' 'under' 'again' 'further' 'then' 'once' 'here' 'there' 'when' 'where' 'why' 'how' 'all' 'any' 'both' 'each' 'few' 'more' 'most' 'other' 'some' 'such' 'no' 'nor' 'not' 'only' 'own' \n",
    "                                         'same' 'so' 'than' 'too' 'very' 's' 't' 'can' 'will' 'just' 'don' 'should' 'now'\n",
    "                                         'java' 'com' 'org' ,'')\n",
    "\n",
    "df1['Description1']= df1['Description1'].str.replace(r'i' 'me' 'my' 'myself' 'we'  'our' 'ours' 'ourselves' 'you' 'your' 'yours' 'yourself''yourselves' 'they' 'we' 'him' 'he' 'him' 'his' 'himself' 'she'\n",
    "                                         'her' 'hers' 'herself' 'it''its' 'itself' 'they' 'them' 'their' 'theirs' 'themselves'  'what' 'which' 'who' 'whom' 'this' 'that' 'these' 'those' 'am' 'is' 'are' 'was' 'were' 'be' 'been' 'being' 'have' 'has' 'had' 'having' 'do' 'does' 'did' 'doing' 'a' 'an' 'the' 'and' 'but' 'if' 'or' 'because' 'as' 'until' 'while' 'of' 'at' 'by' 'for' 'with' 'about' 'against' 'between' 'into' 'through' \n",
    "                                         'during' 'before' 'after' 'above' 'below' 'to' 'from' 'up' 'down' 'in' 'out' 'on' 'off' 'over' 'under' 'again' 'further' 'then' 'once' \n",
    "                                         'here' 'there' 'when' 'where' 'why' 'how' 'all' 'any' 'both' 'each' 'few' 'more' 'most' 'other' 'some' 'such' 'no' 'nor' 'not' 'only' 'own' 'same' 'so' 'than' 'too' 'very' 's' 't' 'can' 'will' 'just' 'don' 'should' 'now'\n",
    "                                         'java' 'com' 'org' ,'')\n",
    "\n",
    "df1['Description2']= df1['Description2'].str.replace(r'i' 'me' 'my' 'myself' 'we' 'our' 'ours' 'ourselves' 'you' 'your' 'yours' 'yourself''yourselves' 'they' 'we' 'him' 'he' 'him' 'his' 'himself' 'she'\n",
    "                                         'her' 'hers' 'herself' 'it''its' 'itself' 'they' 'them' 'their' 'theirs' 'themselves'  'what' 'which' 'who' 'whom' 'this' 'that' 'these' 'those' 'am' 'is' 'are' 'was' 'were' 'be' 'been' 'being' 'have' 'has' 'had' 'having' 'do' 'does' 'did' 'doing' 'a' 'an'\n",
    "                                         'the' 'and' 'but' 'if' 'or' 'because' 'as' 'until' 'while' 'of' 'at' 'by' 'for' 'with' 'about' 'against' 'between' 'into' 'through' \n",
    "                                         'during' 'before' 'after' 'above' 'below' 'to' 'from' 'up' 'down' 'in' 'out' 'on' 'off' 'over' 'under' 'again' 'further' 'then' 'once' 'here' 'there' 'when' 'where' 'why' 'how' 'all' 'any' 'both' 'each' 'few' 'more' 'most' 'other' 'some' 'such' 'no' 'nor' 'not' 'only' 'own' \n",
    "                                         'same' 'so' 'than' 'too' 'very' 's' 't' 'can' 'will' 'just' 'don' 'should' 'now'\n",
    "                                         'java' 'com' 'org' ,'')\n",
    "\n",
    "df2['Description1']= df2['Description1'].str.replace(r'i' 'me' 'my' 'myself' 'we' 'our' 'ours' 'ourselves' 'you' 'your' 'yours' 'yourself''yourselves' 'they' 'we' 'him' 'he' 'him' 'his' 'himself' 'she'\n",
    "                                         'her' 'hers' 'herself' 'it''its' 'itself' 'they' 'them' 'their' 'theirs' 'themselves'  'what' 'which' 'who' 'whom' 'this' 'that' 'these' 'those' 'am' 'is' 'are' 'was' 'were' 'be' 'been' 'being' 'have' 'has' 'had' 'having' 'do' 'does' 'did' 'doing' 'a' 'an'\n",
    "                                         'the' 'and' 'but' 'if' 'or' 'because' 'as' 'until' 'while' 'of' 'at' 'by' 'for' 'with' 'about' 'against' 'between' 'into' 'through' 'during' 'before' 'after' 'above' 'below' 'to' 'from' 'up' 'down' 'in' 'out' 'on' 'off' 'over' 'under' 'again' 'further' 'then' 'once' \n",
    "                                         'here' 'there' 'when' 'where' 'why' 'how' 'all' 'any' 'both' 'each' 'few' 'more' 'most' 'other' 'some' 'such' 'no' 'nor' 'not' 'only' 'own' 'same' 'so' 'than' 'too' 'very' 's' 't' 'can' 'will' 'just' 'don' 'should' 'now'\n",
    "                                         'java' 'com' 'org' ,'')\n",
    "\n",
    "df2['Description2']= df2['Description2'].str.replace(r'i' 'me' 'my' 'myself' 'we' 'our' 'ours' 'ourselves' 'you' 'your' 'yours' 'yourself''yourselves' 'they' 'we' 'him' 'he' 'him' 'his' 'himself' 'she'\n",
    "                                         'her' 'hers' 'herself' 'it''its' 'itself' 'they' 'them' 'their' 'theirs' 'themselves'  'what' 'which' 'who' 'whom' 'this' 'that' 'these' 'those' 'am' 'is' 'are' 'was' 'were' 'be' 'been' 'being' 'have' 'has' 'had' 'having' 'do' 'does' 'did' 'doing' 'a' 'an'\n",
    "                                         'the' 'and' 'but' 'if' 'or' 'because' 'as' 'until' 'while' 'of' 'at' 'by' 'for' 'with' 'about' 'against' 'between' 'into' 'through' 'during' 'before' 'after' 'above' 'below' 'to' 'from' 'up' 'down' 'in' 'out' 'on' 'off' 'over' 'under' 'again' 'further' 'then' 'once' \n",
    "                                         'here' 'there' 'when' 'where' 'why' 'how' 'all' 'any' 'both' 'each' 'few' 'more' 'most' 'other' 'some' 'such' 'no' 'nor' 'not' 'only' 'own'  'same' 'so' 'than' 'too' 'very' 's' 't' 'can' 'will' 'just' 'don' 'should' 'now'\n",
    "                                         'java' 'com' 'org' ,'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e5c1f0-ed99-4509-909f-4589e4a28a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#**Batch ThunderBird**\"\"\"\n",
    "\n",
    "batch_31=df1[:500]\n",
    "batch_32=df2[:500]\n",
    "df3 = pd.concat([batch_31,batch_32], ignore_index=True)\n",
    "batch_41=df1[500:1000]\n",
    "batch_42=df2[500:1000]\n",
    "df4 = pd.concat([batch_41,batch_42], ignore_index=True)\n",
    "batch_51=df1[1000:1500]\n",
    "batch_52=df2[1000:1500]\n",
    "df5 = pd.concat([batch_51,batch_52], ignore_index=True)\n",
    "batch_61=df1[1500:2000]\n",
    "batch_62=df2[1500:2000]\n",
    "df6 = pd.concat([batch_61,batch_62], ignore_index=True)\n",
    "batch_71=df1[2000:2500]\n",
    "batch_72=df2[2000:2500]\n",
    "df7 = pd.concat([batch_71,batch_72], ignore_index=True)\n",
    "batch_81=df1[2500:3000]\n",
    "batch_82=df2[2500:3000]\n",
    "df8 = pd.concat([batch_81,batch_82], ignore_index=True)\n",
    "batch_91=df1[3000:3486]\n",
    "batch_92=df2[3000:3486]\n",
    "df9 = pd.concat([batch_91,batch_92], ignore_index=True)\n",
    "\n",
    "\n",
    "#Testing\n",
    "batch_101=df1[3486:3900]\n",
    "batch_102=df2[3486:3900]\n",
    "df10 = pd.concat([batch_101,batch_102], ignore_index=True)\n",
    "batch_111=df1[3900:4338]\n",
    "batch_112=df2[3900:4374]\n",
    "df11 = pd.concat([batch_111,batch_112], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870049ae-e8c9-4dbc-b4ee-fae12402aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" **_get_segments3** \"\"\"\n",
    "\n",
    "def _get_segments3(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = False\n",
    "    current_segment_id = 0 \n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        #print(token)\n",
    "        if token == 102:\n",
    "            #if first_sep:\n",
    "                #first_sep = False \n",
    "            #else:\n",
    "           current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bb8b37-b4b5-44c9-bd7a-c2e17d80cc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63437426,  0.16888922, -0.14908312, ..., -0.91008127,\n",
       "         0.49243158,  0.39527002],\n",
       "       [-0.86823285, -0.02189723, -0.87252784, ..., -0.750787  ,\n",
       "        -0.35492542,  0.53155196],\n",
       "       [-1.1551882 ,  0.15181172, -0.57454187, ..., -1.1509806 ,\n",
       "         0.18466112,  0.4683906 ],\n",
       "       ...,\n",
       "       [-0.8019993 , -0.05860963, -0.54805595, ..., -0.49166897,\n",
       "        -0.4750937 ,  0.57364607],\n",
       "       [-0.58294255, -0.37753618, -0.68710047, ..., -0.58758396,\n",
       "        -0.3116894 ,  0.76088023],\n",
       "       [-0.68465036,  0.08893419, -0.22074428, ..., -0.72961   ,\n",
       "        -0.24730429,  0.75543016]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#**df3**\"\"\"\n",
    "\n",
    "pair3= df3['Title1'] +  [\" [SEP] \"] + df3['Title2']\n",
    "tokenized3 = pair3.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=300)))\n",
    "\n",
    "max_len3 = 0                 # padding all lists to the same size\n",
    "for i in tokenized3.values:\n",
    "    if len(i) > max_len3:\n",
    "        max_len3 = len(i)\n",
    "max_len3 =300\n",
    "padded3 = np.array([i + [0]*(max_len3-len(i)) for i in tokenized3.values])\n",
    "\n",
    "np.array(padded3).shape\n",
    "\n",
    "attention_mask3 = np.where(padded3 != 0, 1, 0)\n",
    "attention_mask3.shape\n",
    "input_ids3 = torch.tensor(padded3)  \n",
    "attention_mask3 = torch.tensor(attention_mask3)\n",
    "input_segments3= np.array([_get_segments3(token, max_len3)for token in tokenized3.values])\n",
    "token_type_ids3 = torch.tensor(input_segments3)\n",
    "input_segments3 = torch.tensor(input_segments3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states3 = model(input_ids3, attention_mask=attention_mask3, token_type_ids=input_segments3)    # <<< 600 rows only !!!\n",
    "features3 = last_hidden_states3[0][:,0,:].numpy()\n",
    "features3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f55f8e-45e0-48a3-acd0-340e29f1debb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6266525 ,  0.11180539, -0.5889019 , ..., -0.6529992 ,\n",
       "         0.17653076,  0.5426795 ],\n",
       "       [-0.8718555 ,  0.2191143 , -0.54610837, ..., -0.7210032 ,\n",
       "         0.25231126,  0.69797134],\n",
       "       [-0.54135114, -0.16320094, -0.49228886, ..., -0.5846044 ,\n",
       "         0.2484964 ,  0.38142914],\n",
       "       ...,\n",
       "       [-0.77846956,  0.14806286, -0.11027688, ..., -0.5818037 ,\n",
       "        -0.01222107,  0.69179934],\n",
       "       [-0.40279952, -0.18381521, -0.24047273, ..., -0.6942398 ,\n",
       "         0.10408735,  0.6606819 ],\n",
       "       [-0.2847792 , -0.36139387, -0.04779038, ..., -0.7428371 ,\n",
       "        -0.24323756,  0.5644962 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#**df4**\"\"\"\n",
    "\n",
    "pair4= df4['Title1'] +  [\" [SEP] \"] + df4['Title2']\n",
    "tokenized4 = pair4.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=300)))\n",
    "max_len4 = 0                 # padding all lists to the same size\n",
    "for i in tokenized4.values:\n",
    "    if len(i) > max_len4:\n",
    "        max_len4 = len(i)\n",
    "max_len4 =300\n",
    "padded4 = np.array([i + [0]*(max_len4-len(i)) for i in tokenized4.values])\n",
    "\n",
    "np.array(padded4).shape\n",
    "\n",
    "attention_mask4 = np.where(padded4 != 0, 1, 0)\n",
    "attention_mask4.shape\n",
    "input_ids4 = torch.tensor(padded4)  \n",
    "attention_mask4 = torch.tensor(attention_mask4)\n",
    "input_segments4= np.array([_get_segments3(token, max_len4)for token in tokenized4.values])\n",
    "token_type_ids4 = torch.tensor(input_segments4)\n",
    "input_segments4 = torch.tensor(input_segments4)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states4 = model(input_ids4, attention_mask=attention_mask4, token_type_ids=input_segments4)   \n",
    "features4 = last_hidden_states4[0][:,0,:].numpy()\n",
    "features4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6696efd-b5f4-4dca-b228-063316676e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#**df5**\"\"\"\n",
    "\n",
    "pair5= df5['Title1'] +  [\" [SEP] \"] + df5['Title2']\n",
    "tokenized5 = pair5.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=300)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511f0e41-442f-48e7-9570-3fd6eab5cf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"##**Padding**\"\"\"\n",
    "\n",
    "max_len5 = 0                 # padding all lists to the same size\n",
    "for i in tokenized5.values:\n",
    "    if len(i) > max_len5:\n",
    "        max_len5 = len(i)\n",
    "\n",
    "max_len5 =300\n",
    "padded5 = np.array([i + [0]*(max_len5-len(i)) for i in tokenized5.values])\n",
    "\n",
    "np.array(padded5).shape        # Dimensions of the padded variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3728b1ed-39b9-4984-bd99-c28d137cf05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"##**Masking**\"\"\"\n",
    "\n",
    "attention_mask5 = np.where(padded5 != 0, 1, 0)\n",
    "attention_mask5.shape\n",
    "input_ids5 = torch.tensor(padded5)  \n",
    "attention_mask5 = torch.tensor(attention_mask5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57bad210-85fd-4b03-9013-29a6523ddcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"##**Running the `model()` function through BERT**\"\"\"\n",
    "\n",
    "input_segments5= np.array([_get_segments3(token, max_len5)for token in tokenized5.values])\n",
    "token_type_ids5 = torch.tensor(input_segments5)\n",
    "input_segments5 = torch.tensor(input_segments5)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states5 = model(input_ids5, attention_mask=attention_mask5, token_type_ids=input_segments5)    # <<< 600 rows only !!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96cfecd5-ed74-4849-831c-5362a1e0bb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9109529 , -0.05337809, -0.30842963, ..., -0.9966681 ,\n",
       "         0.15199786,  0.20217186],\n",
       "       [-0.5676509 ,  0.08843837, -0.5360164 , ..., -0.8554502 ,\n",
       "        -0.15221055,  0.53532135],\n",
       "       [-0.7333582 ,  0.1683239 , -0.65668756, ..., -0.86305934,\n",
       "         0.16315599,  0.528179  ],\n",
       "       ...,\n",
       "       [-0.40766814, -0.21933427, -0.4188956 , ..., -0.580876  ,\n",
       "        -0.18957658,  0.16838819],\n",
       "       [-0.37387398,  0.03596683, -0.3334533 , ..., -0.7031253 ,\n",
       "         0.30394775,  0.33992627],\n",
       "       [-0.77783126, -0.11517579, -0.38509107, ..., -0.6621041 ,\n",
       "        -0.23336115,  0.9779235 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"##**Slicing the part of the output of BERT : [cls]**\"\"\"\n",
    "\n",
    "features5 = last_hidden_states5[0][:,0,:].numpy()\n",
    "features5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "014e3745-8ff0-4f57-9ead-24234ecec0f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m input_segments6 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input_segments6)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 25\u001b[0m     last_hidden_states6 \u001b[38;5;241m=\u001b[39m model(input_ids6, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask6, token_type_ids\u001b[38;5;241m=\u001b[39minput_segments6)   \n\u001b[0;32m     26\u001b[0m features6 \u001b[38;5;241m=\u001b[39m last_hidden_states6[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     27\u001b[0m features6\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1142\u001b[0m     embedding_output,\n\u001b[0;32m   1143\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1144\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1145\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1146\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1147\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1148\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1149\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1150\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1151\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1152\u001b[0m )\n\u001b[0;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    685\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m         output_attentions,\n\u001b[0;32m    692\u001b[0m     )\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    695\u001b[0m         hidden_states,\n\u001b[0;32m    696\u001b[0m         attention_mask,\n\u001b[0;32m    697\u001b[0m         layer_head_mask,\n\u001b[0;32m    698\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    699\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    700\u001b[0m         past_key_value,\n\u001b[0;32m    701\u001b[0m         output_attentions,\n\u001b[0;32m    702\u001b[0m     )\n\u001b[0;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    628\u001b[0m )\n\u001b[0;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\transformers\\pytorch_utils.py:239\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 551\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\SDPtest\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"#**df6**\"\"\"\n",
    "\n",
    "pair6= df6['Title1'] +  [\" [SEP] \"] + df6['Title2']\n",
    "tokenized6 = pair6.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=300)))\n",
    "\n",
    "max_len6 = 0                 # padding all lists to the same size\n",
    "for i in tokenized6.values:\n",
    "    if len(i) > max_len6:\n",
    "        max_len6 = len(i)\n",
    "\n",
    "max_len6=300\n",
    "padded6 = np.array([i + [0]*(max_len6-len(i)) for i in tokenized6.values])\n",
    "\n",
    "np.array(padded6).shape        # Dimensions of the padded variable        \n",
    "\n",
    "attention_mask6 = np.where(padded6 != 0, 1, 0)\n",
    "attention_mask6.shape\n",
    "input_ids6 = torch.tensor(padded6)  \n",
    "attention_mask6 = torch.tensor(attention_mask6)\n",
    "input_segments6= np.array([_get_segments3(token, max_len6)for token in tokenized6.values])\n",
    "token_type_ids6 = torch.tensor(input_segments6)\n",
    "input_segments6 = torch.tensor(input_segments6)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states6 = model(input_ids6, attention_mask=attention_mask6, token_type_ids=input_segments6)   \n",
    "features6 = last_hidden_states6[0][:,0,:].numpy()\n",
    "features6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524dbc0-0565-494c-94d4-d4b64679c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#**df7**\"\"\"\n",
    "pair7= df7['Title1'] +  [\" [SEP] \"] + df7['Title2']\n",
    "tokenized7 = pair7.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=300)))\n",
    "\n",
    "max_len7 = 0                 # padding all lists to the same size\n",
    "for i in tokenized7.values:\n",
    "    if len(i) > max_len7:\n",
    "        max_len7 = len(i)\n",
    "\n",
    "max_len7=300\n",
    "padded7 = np.array([i + [0]*(max_len7-len(i)) for i in tokenized7.values])\n",
    "\n",
    "np.array(padded7).shape        # Dimensions of the padded variable    \n",
    "\n",
    "attention_mask7 = np.where(padded7 != 0, 1, 0)\n",
    "attention_mask7.shape\n",
    "input_ids7 = torch.tensor(padded7)  \n",
    "attention_mask7 = torch.tensor(attention_mask7)\n",
    "input_segments7= np.array([_get_segments3(token, max_len7)for token in tokenized7.values])\n",
    "token_type_ids7 = torch.tensor(input_segments7)\n",
    "input_segments7 = torch.tensor(input_segments7)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states7 = model(input_ids7, attention_mask=attention_mask7, token_type_ids=input_segments7)  \n",
    "features7 = last_hidden_states7[0][:,0,:].numpy()\n",
    "features7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98157005-4e9f-4b58-beec-043babc75316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#**df8**\"\"\"\n",
    "pair8= df8['Title1'] +  [\" [SEP] \"] + df8['Title2']\n",
    "tokenized8 = pair8.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=300)))\n",
    "\n",
    "max_len8 = 0                 # padding all lists to the same size\n",
    "for i in tokenized8.values:\n",
    "    if len(i) > max_len8:\n",
    "        max_len8 = len(i)\n",
    "max_len8=300\n",
    "padded8 = np.array([i + [0]*(max_len8-len(i)) for i in tokenized8.values])\n",
    "\n",
    "np.array(padded8).shape        # Dimensions of the padded variable  \n",
    "\n",
    "\n",
    "attention_mask8 = np.where(padded8 != 0, 1, 0)\n",
    "attention_mask8.shape\n",
    "input_ids8 = torch.tensor(padded8)  \n",
    "attention_mask8 = torch.tensor(attention_mask8)\n",
    "input_segments8= np.array([_get_segments3(token, max_len8)for token in tokenized8.values])\n",
    "token_type_ids8 = torch.tensor(input_segments8)\n",
    "input_segments8 = torch.tensor(input_segments8)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states8 = model(input_ids8, attention_mask=attention_mask8, token_type_ids=input_segments8)   \n",
    "features8 = last_hidden_states8[0][:,0,:].numpy()\n",
    "features8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5782966-33a1-447e-8372-3f5ba247feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#**df9**\"\"\"\n",
    "pair9= df9['Title1'] +  [\" [SEP] \"] + df9['Title2']\n",
    "tokenized9 = pair9.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=300)))\n",
    "\n",
    "max_len9 = 0                 # padding all lists to the same size\n",
    "for i in tokenized9.values:\n",
    "    if len(i) > max_len9:\n",
    "        max_len9 = len(i)\n",
    "max_len9=300\n",
    "padded9 = np.array([i + [0]*(max_len9-len(i)) for i in tokenized9.values])\n",
    "\n",
    "np.array(padded9).shape        # Dimensions of the padded variable    \n",
    "\n",
    "attention_mask9 = np.where(padded9 != 0, 1, 0)\n",
    "attention_mask9.shape\n",
    "input_ids9 = torch.tensor(padded9)  \n",
    "attention_mask9 = torch.tensor(attention_mask9)\n",
    "input_segments9= np.array([_get_segments3(token, max_len9)for token in tokenized9.values])\n",
    "token_type_ids9 = torch.tensor(input_segments9)\n",
    "input_segments9 = torch.tensor(input_segments9)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states9 = model(input_ids9, attention_mask=attention_mask9, token_type_ids=input_segments9)    \n",
    "features9 = last_hidden_states9[0][:,0,:].numpy()\n",
    "features9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3571e-845d-490f-a740-96a8a800c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#**df10**\"\"\"\n",
    "\n",
    "pair10= df10['Title1'] +  [\" [SEP] \"] + df10['Title2']\n",
    "tokenized10 = pair10.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=300)))\n",
    "max_len10 = 0                 # padding all lists to the same size\n",
    "for i in tokenized10.values:\n",
    "    if len(i) > max_len10:\n",
    "        max_len10 = len(i)\n",
    "max_len10=300\n",
    "padded10 = np.array([i + [0]*(max_len10-len(i)) for i in tokenized10.values])\n",
    "\n",
    "np.array(padded10).shape        # Dimensions of the padded variable\n",
    "\n",
    "attention_mask10 = np.where(padded10 != 0, 1, 0)\n",
    "attention_mask10.shape\n",
    "input_ids10 = torch.tensor(padded10)  \n",
    "attention_mask10 = torch.tensor(attention_mask10)\n",
    "input_segments10= np.array([_get_segments3(token, max_len10)for token in tokenized10.values])\n",
    "token_type_ids10 = torch.tensor(input_segments10)\n",
    "input_segments10 = torch.tensor(input_segments10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states10 = model(input_ids10, attention_mask=attention_mask10, token_type_ids=input_segments10) \n",
    "features10 = last_hidden_states10[0][:,0,:].numpy()\n",
    "features10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f42d6-d2fc-437f-a6eb-3d2d2d1a1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#**df11**\"\"\"\n",
    "\n",
    "pair11= df11['Title1'] +  [\" [SEP] \"] + df11['Title2']\n",
    "tokenized11 = pair11.apply((lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=300)))\n",
    "\n",
    "max_len11 = 0                 # padding all lists to the same size\n",
    "for i in tokenized11.values:\n",
    "    if len(i) > max_len11:\n",
    "        max_len11 = len(i)\n",
    "max_len11=300\n",
    "padded11 = np.array([i + [0]*(max_len11-len(i)) for i in tokenized11.values])\n",
    "\n",
    "np.array(padded11).shape        # Dimensions of the padded variable   \n",
    "\n",
    "attention_mask11 = np.where(padded11 != 0, 1, 0)\n",
    "attention_mask11.shape\n",
    "input_ids11 = torch.tensor(padded11)  \n",
    "attention_mask11 = torch.tensor(attention_mask11)\n",
    "input_segments11= np.array([_get_segments3(token, max_len11)for token in tokenized11.values])\n",
    "token_type_ids11 = torch.tensor(input_segments11)\n",
    "input_segments11 = torch.tensor(input_segments11)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states11 = model(input_ids11, attention_mask=attention_mask11, token_type_ids=input_segments11)   \n",
    "features11 = last_hidden_states11[0][:,0,:].numpy()\n",
    "features11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f54ccf-dfbb-4934-9052-07192fc01b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#**Classification**\"\"\"\n",
    "\n",
    "\n",
    "features=np.concatenate([features3,features4,features5,features6,features7,features8,features9,features10,features11])\n",
    "\n",
    "features.shape\n",
    "\n",
    "Total = pd.concat([df3,df4,df5,df6,df7,df8,df9,df10,df11], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "labels =Total['Label']\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66dad3-1eca-492a-9aaa-5461ca45becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hold out \"\"\"\n",
    "\n",
    "# for thunderbird\n",
    "train_features = features[0:6792]\n",
    "train_labels = labels[0:6792]\n",
    "test_features = features[6792:]\n",
    "test_labels = labels[6792:]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999f844-14f8-4289-a7d9-4816b9322719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b8346-c9a8-48db-8709-35863eb2e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# **MLP Classifier**\"\"\"\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,100,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "\n",
    "\n",
    "y_true, y_pred = test_labels , clf.predict(test_features)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36288bd0-aea4-42a3-bc58-5616dd2fa1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb9848-7d0d-4546-9819-602bbead7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results on the test set:')\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
